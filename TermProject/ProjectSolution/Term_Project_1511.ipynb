{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xc0UqsL7w6nS"
      },
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0QtQ0N7w9uZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet\n",
        "from sklearn.metrics import classification_report\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import re\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryj9PJD-xPL5"
      },
      "source": [
        "## Necessary Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Rk5bt8UxUQH",
        "outputId": "59c5e303-1f1b-4815-9b7e-dba5555e5284"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Download necessary NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrNfRaELxKfD"
      },
      "outputs": [],
      "source": [
        "def get_wordnet_pos(treebank_tag):\n",
        "    \"\"\"Converts treebank tags to wordnet tags.\"\"\"\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return None  # Return None if there is no match\n",
        "\n",
        "def process_text(text):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    # Perform POS tagging\n",
        "    tagged_tokens = pos_tag(tokens)\n",
        "\n",
        "    lemmatized_tokens = []\n",
        "    for word, tag in tagged_tokens:\n",
        "        if word.lower() not in stop_words:\n",
        "            pos = get_wordnet_pos(tag)\n",
        "            if pos:\n",
        "                lemmatized_word = lemmatizer.lemmatize(word, pos)\n",
        "            else:\n",
        "                lemmatized_word = lemmatizer.lemmatize(word)\n",
        "            lemmatized_tokens.append(lemmatized_word.lower())\n",
        "\n",
        "    return lemmatized_tokens\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'\\b(js|Js|JS)\\b', 'javascript', text)\n",
        "    text = re.sub(r'\\b(os|OS|Os)\\b', 'osx', text)\n",
        "    text = re.sub(r'\\b(css|CSS)\\b', 'cascadingstylesheet', text)\n",
        "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
        "    text = re.sub(r\"[^a-zA-Z0-9'\\s]\", \" \", text)\n",
        "    text = \" \".join(text.split())\n",
        "    return text\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing Step"
      ],
      "metadata": {
        "id": "esn9VRnxizdf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLe4vM2DxWps"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load data\n",
        "bugs_data = pd.read_csv('bugs-train.csv')\n",
        "\n",
        "bugs_data['clean_summary'] = bugs_data['summary'].apply(clean_text)\n",
        "\n",
        "bugs_data['lemmatized_tokens'] = bugs_data['clean_summary'].apply(process_text)\n",
        "\n",
        "bugs_data['processed_text'] = bugs_data['lemmatized_tokens'].apply(lambda tokens: ' '.join(tokens))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Io1BYmg7C5Tr"
      },
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "bugs_data['encoded_severity'] = label_encoder.fit_transform(bugs_data['severity'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "LAmu8VUsyyQV",
        "outputId": "6681e7c3-e060-49f3-e8c5-ea78541967ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   bug_id                                            summary  severity  \\\n",
              "0  365569                  Remove workaround from bug 297227    normal   \n",
              "1  365578    Print Preview crashes on any URL in gtk2 builds  critical   \n",
              "2  365582                     Lines are not showing in table     major   \n",
              "3  365584  Firefox render ÛÏsimplified ArabicÛ font fa...    normal   \n",
              "4  365597             Crash [@ nsINodeInfo::NodeInfoManager]  critical   \n",
              "\n",
              "                                       clean_summary  \\\n",
              "0                  Remove workaround from bug 297227   \n",
              "1    Print Preview crashes on any URL in gtk2 builds   \n",
              "2                     Lines are not showing in table   \n",
              "3  Firefox render simplified Arabic font face inc...   \n",
              "4                  Crash nsINodeInfo NodeInfoManager   \n",
              "\n",
              "                                   lemmatized_tokens  \\\n",
              "0                  [remove, workaround, bug, 297227]   \n",
              "1          [print, preview, crash, url, gtk2, build]   \n",
              "2                               [lines, show, table]   \n",
              "3  [firefox, render, simplify, arabic, font, face...   \n",
              "4              [crash, nsinodeinfo, nodeinfomanager]   \n",
              "\n",
              "                                      processed_text  encoded_severity  \n",
              "0                       remove workaround bug 297227                 5  \n",
              "1                 print preview crash url gtk2 build                 1  \n",
              "2                                   lines show table                 3  \n",
              "3  firefox render simplify arabic font face incor...                 5  \n",
              "4                  crash nsinodeinfo nodeinfomanager                 1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa02ef8c-91bd-40b0-8d4d-8f11d3f2463d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bug_id</th>\n",
              "      <th>summary</th>\n",
              "      <th>severity</th>\n",
              "      <th>clean_summary</th>\n",
              "      <th>lemmatized_tokens</th>\n",
              "      <th>processed_text</th>\n",
              "      <th>encoded_severity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>365569</td>\n",
              "      <td>Remove workaround from bug 297227</td>\n",
              "      <td>normal</td>\n",
              "      <td>Remove workaround from bug 297227</td>\n",
              "      <td>[remove, workaround, bug, 297227]</td>\n",
              "      <td>remove workaround bug 297227</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>365578</td>\n",
              "      <td>Print Preview crashes on any URL in gtk2 builds</td>\n",
              "      <td>critical</td>\n",
              "      <td>Print Preview crashes on any URL in gtk2 builds</td>\n",
              "      <td>[print, preview, crash, url, gtk2, build]</td>\n",
              "      <td>print preview crash url gtk2 build</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>365582</td>\n",
              "      <td>Lines are not showing in table</td>\n",
              "      <td>major</td>\n",
              "      <td>Lines are not showing in table</td>\n",
              "      <td>[lines, show, table]</td>\n",
              "      <td>lines show table</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>365584</td>\n",
              "      <td>Firefox render ÛÏsimplified ArabicÛ font fa...</td>\n",
              "      <td>normal</td>\n",
              "      <td>Firefox render simplified Arabic font face inc...</td>\n",
              "      <td>[firefox, render, simplify, arabic, font, face...</td>\n",
              "      <td>firefox render simplify arabic font face incor...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>365597</td>\n",
              "      <td>Crash [@ nsINodeInfo::NodeInfoManager]</td>\n",
              "      <td>critical</td>\n",
              "      <td>Crash nsINodeInfo NodeInfoManager</td>\n",
              "      <td>[crash, nsinodeinfo, nodeinfomanager]</td>\n",
              "      <td>crash nsinodeinfo nodeinfomanager</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa02ef8c-91bd-40b0-8d4d-8f11d3f2463d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aa02ef8c-91bd-40b0-8d4d-8f11d3f2463d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aa02ef8c-91bd-40b0-8d4d-8f11d3f2463d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9417a3d2-0661-4b1e-9e6b-fa397e5f3b5e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9417a3d2-0661-4b1e-9e6b-fa397e5f3b5e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9417a3d2-0661-4b1e-9e6b-fa397e5f3b5e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "bugs_data"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "bugs_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQobUxbFzjIe",
        "outputId": "96bf2ce9-8164-4deb-fd27-1c78b9361842"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "severity\n",
              "normal         125854\n",
              "critical        18658\n",
              "major            6053\n",
              "enhancement      4426\n",
              "minor            3102\n",
              "trivial          1204\n",
              "blocker           701\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "bugs_data['severity'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try 1 - Neural Network"
      ],
      "metadata": {
        "id": "dncCA5q4jJtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = bugs_data['processed_text']\n",
        "labels = bugs_data['severity']\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X = vectorizer.fit_transform(texts).toarray()\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "X_train_torch = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test_torch = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train_torch = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test_torch = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "\n",
        "train_data = TensorDataset(X_train_torch, y_train_torch)\n",
        "train_loader = DataLoader(train_data, batch_size=64)"
      ],
      "metadata": {
        "id": "sPFZEgFljOUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class TextClassifier(nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super(TextClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(num_features, 512)  # First layer\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(512, 256)  # Second layer\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc3 = nn.Linear(256, 128)  # Third layer\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.dropout3 = nn.Dropout(0.5)\n",
        "        self.fc4 = nn.Linear(128, num_classes)  # Output layer\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.dropout3(x)\n",
        "        x = self.fc4(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "model = TextClassifier(num_features=1000, num_classes=len(label_encoder.classes_))\n"
      ],
      "metadata": {
        "id": "w0uXjKuNjRNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs, targets in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')"
      ],
      "metadata": {
        "id": "Y1zUFA2WjSuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# Prediction\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test_torch)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "precision = precision_score(y_test_torch.numpy(), predicted.numpy(), average='macro')\n",
        "print(f'Macro Precision: {precision}')\n",
        "\n",
        "cm = confusion_matrix(y_test_torch.numpy(), predicted.numpy())\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "peq2yhbSjUuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try 1 - Predictions"
      ],
      "metadata": {
        "id": "7frtBBunjXsm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning the test data"
      ],
      "metadata": {
        "id": "F41oo3x3l2qA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('bugs-test.csv')\n",
        "\n",
        "df_test['clean_summary'] = df_test['summary'].apply(clean_text)\n",
        "\n",
        "df_test['lemmatized_tokens'] = df_test['clean_summary'].apply(process_text)\n",
        "\n",
        "df_test['processed_text'] = df_test['lemmatized_tokens'].apply(lambda tokens: ' '.join(tokens))"
      ],
      "metadata": {
        "id": "hvBgVgQljXdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make predictions"
      ],
      "metadata": {
        "id": "gOBxN1hvmPRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_test = vectorizer.transform(df_test['processed_text'].fillna(\" \"))  # Replace NaN with empty strings"
      ],
      "metadata": {
        "id": "IKQchXyfji_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_tensor = torch.tensor(tfidf_test.toarray(), dtype=torch.float32)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(test_tensor)\n",
        "    _, predicted = torch.max(outputs, 1)\n"
      ],
      "metadata": {
        "id": "a5aEXbR4jjz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels = predicted.numpy()\n",
        "\n",
        "predicted_labels = label_encoder.inverse_transform(predicted_labels)\n",
        "\n",
        "df_test['severity'] = predicted_labels\n"
      ],
      "metadata": {
        "id": "LTXOs878jlQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df_test.drop(['summary', 'clean_summary', 'lemmatized_tokens', 'processed_text'], axis=1)"
      ],
      "metadata": {
        "id": "vA0WYvzRjpFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.to_csv('updated_bugs_test.csv', index=False)"
      ],
      "metadata": {
        "id": "cFPaCKSOjq3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try 2 - Stack Ensemble"
      ],
      "metadata": {
        "id": "XRNt3ZrnlhON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, train_test_split\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "file_path = 'bugs-train.csv'\n",
        "bugs_data = pd.read_csv(file_path)\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "\n",
        "    text = re.sub(r'[^a-zA-Z0-9/:_\\-\\[\\]]', ' ', text)\n",
        "\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    cleaned_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "\n",
        "    cleaned_text = ' '.join(cleaned_tokens)\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "bugs_data['cleaned_summary'] = bugs_data['summary'].apply(clean_text)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "bugs_data['severity_encoded'] = label_encoder.fit_transform(bugs_data['severity'])\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
        "\n",
        "preprocessor = Pipeline(steps=[\n",
        "    ('tfidf', tfidf_vectorizer),\n",
        "    ('scaler', StandardScaler(with_mean=False))\n",
        "])\n",
        "\n",
        "X_transformed = preprocessor.fit_transform(bugs_data['cleaned_summary'])\n",
        "y = bugs_data['severity_encoded']\n",
        "\n",
        "base_models = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42, n_jobs=-1)),\n",
        "    ('xgb', XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=5, use_label_encoder=False, eval_metric='mlogloss', random_state=42, n_jobs=-1)),\n",
        "    ('mlp', MLPClassifier(hidden_layer_sizes=(100,), alpha=0.001, max_iter=300, random_state=42))\n",
        "]\n",
        "\n",
        "stacking_model = StackingClassifier(\n",
        "    estimators=base_models,\n",
        "    final_estimator=LogisticRegression(max_iter=1000, n_jobs=-1)\n",
        ")\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cross_val_scores = cross_val_score(stacking_model, X_transformed, y, cv=kf, scoring='precision_macro', n_jobs=-1)\n",
        "\n",
        "print(f'Cross-validation scores (Macro Precision): {cross_val_scores}')\n",
        "print(f'Average cross-validation score (Macro Precision): {cross_val_scores.mean()}')\n",
        "\n",
        "stacking_model.fit(X_transformed, y)"
      ],
      "metadata": {
        "id": "XLSNijkMlkfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try 2 - Predictions\n"
      ],
      "metadata": {
        "id": "eYnWZ39zlx-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning the test data\n",
        "\n"
      ],
      "metadata": {
        "id": "bkFFCSLVjx0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_file_path = 'bugs-test.csv'\n",
        "bugs_test_data = pd.read_csv(test_file_path)\n",
        "\n",
        "bugs_test_data['cleaned_summary'] = bugs_test_data['summary'].apply(clean_text)"
      ],
      "metadata": {
        "id": "AT-uFtjHl3_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make Predictions\n"
      ],
      "metadata": {
        "id": "oDsGUDH_MH4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_data_transformed = preprocessor.transform(bugs_test_data['cleaned_summary'])\n",
        "\n",
        "predicted_severity_encoded = stacking_model.predict(X_test_data_transformed)\n",
        "\n",
        "predicted_severity = label_encoder.inverse_transform(predicted_severity_encoded)\n",
        "\n",
        "output_data = pd.DataFrame({\n",
        "    'bug_id': bugs_test_data['bug_id'],\n",
        "    'severity': predicted_severity\n",
        "})\n",
        "\n",
        "output_file_path = 'bugs-test-predicted-10.csv'\n",
        "output_data.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(f\"Output saved to: {output_file_path}\")"
      ],
      "metadata": {
        "id": "zh2QFiaClyTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try 3 - Stacking with LGBM and Random Forest"
      ],
      "metadata": {
        "id": "71XhBTP2MMZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import lightgbm as lgb\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from scipy.stats import randint as sp_randint\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "english_stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\bjs\\b', ' javascript ', text)\n",
        "    text = re.sub(r'\\bos\\b', ' osx ', text)\n",
        "    text = re.sub(r'\\bos x\\b', ' osx ', text)\n",
        "    text = re.sub(r'js_', ' javascript ', text)\n",
        "    text = re.sub(r'@ js', ' javascript ', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    filtered_tokens = [word for word in tokens if word.lower() not in english_stop_words]\n",
        "    return ' '.join(filtered_tokens)\n",
        "\n",
        "data = pd.read_csv('bugs-train.csv')\n",
        "\n",
        "data['summary_preprocessed'] = data['summary'].apply(preprocess)\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(data['severity'])\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_vectorized = vectorizer.fit_transform(data['summary_preprocessed'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "estimators = [\n",
        "    ('random_forest', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "    ('lgbm', lgb.LGBMClassifier(random_state=42))\n",
        "]\n",
        "\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=LogisticRegression(),\n",
        "    stack_method='predict_proba',\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "param_dist = {\n",
        "    'random_forest__n_estimators': sp_randint(50, 200),\n",
        "    'random_forest__max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'random_forest__max_depth': sp_randint(3, 20),\n",
        "    'random_forest__min_samples_split': sp_randint(2, 11),\n",
        "    'random_forest__min_samples_leaf': sp_randint(1, 11),\n",
        "    'lgbm__num_leaves': sp_randint(20, 40),\n",
        "    'lgbm__max_depth': sp_randint(3, 15),\n",
        "    'lgbm__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'lgbm__n_estimators': sp_randint(50, 200)\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=stack_model,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=3,\n",
        "    scoring='accuracy',\n",
        "    cv=3,\n",
        "    random_state=42,\n",
        "    verbose=10,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "best_accuracy = accuracy_score(y_test, y_pred)\n",
        "best_conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "best_class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Best Accuracy: {best_accuracy}')\n",
        "print('Best Confusion Matrix:')\n",
        "print(best_conf_matrix)\n",
        "print('Best Classification Report:')\n",
        "print(best_class_report)"
      ],
      "metadata": {
        "id": "4_LaIfiNMMB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try 3 - Predictions"
      ],
      "metadata": {
        "id": "fsC1btElMewc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning the test data"
      ],
      "metadata": {
        "id": "wATTsobgMjy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the test data\n",
        "test_data = pd.read_csv('bugs-test.csv')\n",
        "\n",
        "# Preprocess the 'summary' column using the same preprocessing function\n",
        "test_data['summary_preprocessed'] = test_data['summary'].apply(preprocess)"
      ],
      "metadata": {
        "id": "MRpf8VqeMg9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make predictions"
      ],
      "metadata": {
        "id": "eKQsfQyyMwLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_new = vectorizer.transform(test_data['summary_preprocessed'])\n",
        "\n",
        "predicted_severity_encoded = best_model.predict(X_test_new)\n",
        "\n",
        "predicted_severity = encoder.inverse_transform(predicted_severity_encoded)\n",
        "\n",
        "result_df = pd.DataFrame({\n",
        "    'bug_id': test_data['bug_id'],\n",
        "    'severity': predicted_severity\n",
        "})\n",
        "\n",
        "result_df.to_csv('predicted_severity.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved to 'predicted_severity.csv'.\")\n"
      ],
      "metadata": {
        "id": "Mg6crhzoMxvU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}